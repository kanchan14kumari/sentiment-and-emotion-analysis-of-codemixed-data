{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPgGDJ6Wlj2FIXbvpTLDrDy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kanchan14kumari/sentiment-and-emotion-analysis-of-codemixed-data/blob/main/Basicmodal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import json\n",
        "\n",
        "\n",
        "# All the sklearn imports\n",
        "from sklearn import metrics\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score\n",
        "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils.validation import check_is_fitted, check_X_y\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.corpus import wordnet, stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Load datasets from CSV files\n",
        "train_df = pd.read_csv(\"preprocessed_train.csv\")\n",
        "test_df = pd.read_csv(\"preprocessed_test.csv\")\n",
        "val_df = pd.read_csv(\"preprocessed_val.csv\")\n",
        "\n",
        "# Fill missing values in each dataset\n",
        "train_df.fillna(\"\", inplace=True)\n",
        "val_df.fillna(\"\", inplace=True)\n",
        "test_df.fillna(\"\", inplace=True)\n",
        "\n",
        "# Separate text and label columns\n",
        "X_train_emotion = train_df['tweet']\n",
        "y_train_emotion = train_df['emotion']\n",
        "\n",
        "X_val_emotion = val_df['tweet']\n",
        "y_val_emotion = val_df['emotion']\n",
        "\n",
        "X_test_emotion = test_df['tweet']\n",
        "y_test_emotion = test_df['emotion']\n",
        "\n",
        "# Vectorizing the text data using TF-IDF for emotion\n",
        "vectorizer_emotion = TfidfVectorizer(sublinear_tf=True, encoding='utf-8', decode_error='ignore', stop_words='english')\n",
        "X_train_tfidf_emotion = vectorizer_emotion.fit_transform(X_train_emotion)\n",
        "X_val_tfidf_emotion = vectorizer_emotion.transform(X_val_emotion)\n",
        "X_test_tfidf_emotion = vectorizer_emotion.transform(X_test_emotion)\n",
        "\n",
        "# Logistic Regression model for emotion\n",
        "lr_model_emotion = LogisticRegression(max_iter=1000)\n",
        "lr_model_emotion.fit(X_train_tfidf_emotion, y_train_emotion)\n",
        "y_pred_lr_emotion = lr_model_emotion.predict(X_test_tfidf_emotion)\n",
        "\n",
        "accuracy_lr = accuracy_score(y_test_emotion, y_pred_lr_emotion)\n",
        "precision_lr = precision_score(y_test_emotion, y_pred_lr_emotion, average='weighted')\n",
        "recall_lr = recall_score(y_test_emotion, y_pred_lr_emotion, average='weighted')\n",
        "f1_score_lr = f1_score(y_test_emotion, y_pred_lr_emotion, average='weighted')\n",
        "\n",
        "\n",
        "print(\"Logistic Regression:\")\n",
        "print(\"Accuracy: \", accuracy_lr)\n",
        "print(\"Precision: \", precision_lr)\n",
        "print(\"Recall: \", recall_lr)\n",
        "print(\"F1 Score: \", f1_score_lr)"
      ],
      "metadata": {
        "id": "E5yrnE_h5TSY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bef6ae54-3045-48c6-d60f-b6fe755ec34a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression:\n",
            "Accuracy:  0.6113333333333333\n",
            "Precision:  0.6439097903913795\n",
            "Recall:  0.6113333333333333\n",
            "F1 Score:  0.5817662722406894\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LSxcdUMM7yFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate text and label columns for sentiment\n",
        "X_train_sentiment = train_df['tweet']\n",
        "y_train_sentiment = train_df['sentiment']\n",
        "\n",
        "X_val_sentiment = val_df['tweet']\n",
        "y_val_sentiment = val_df['sentiment']\n",
        "\n",
        "X_test_sentiment = test_df['tweet']\n",
        "y_test_sentiment = test_df['sentiment']\n",
        "\n",
        "# Vectorizing the text data using TF-IDF for sentiment\n",
        "vectorizer_sentiment = TfidfVectorizer(sublinear_tf=True, encoding='utf-8', decode_error='ignore', stop_words='english')\n",
        "X_train_tfidf_sentiment = vectorizer_sentiment.fit_transform(X_train_sentiment)\n",
        "X_val_tfidf_sentiment = vectorizer_sentiment.transform(X_val_sentiment)\n",
        "X_test_tfidf_sentiment = vectorizer_sentiment.transform(X_test_sentiment)\n",
        "\n",
        "# Logistic Regression model for sentiment\n",
        "lr_model_sentiment = LogisticRegression(max_iter=1000)\n",
        "lr_model_sentiment.fit(X_train_tfidf_sentiment, y_train_sentiment)\n",
        "y_pred_lr_sentiment = lr_model_sentiment.predict(X_test_tfidf_sentiment)\n",
        "\n",
        "accuracy_lr = accuracy_score(y_test_sentiment, y_pred_lr_sentiment)\n",
        "precision_lr = precision_score(y_test_sentiment, y_pred_lr_sentiment, average='weighted')\n",
        "recall_lr = recall_score(y_test_sentiment, y_pred_lr_sentiment, average='weighted')\n",
        "f1_score_lr = f1_score(y_test_sentiment, y_pred_lr_sentiment, average='weighted')\n",
        "\n",
        "\n",
        "print(\"Logistic Regression:\")\n",
        "print(\"Accuracy: \", accuracy_lr)\n",
        "print(\"Precision: \", precision_lr)\n",
        "print(\"Recall: \", recall_lr)\n",
        "print(\"F1 Score: \", f1_score_lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUGF_Rvm7_Am",
        "outputId": "7de80bc2-5f00-48d9-a11d-bc406428f67a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression:\n",
            "Accuracy:  0.6593333333333333\n",
            "Precision:  0.6626375636850009\n",
            "Recall:  0.6593333333333333\n",
            "F1 Score:  0.660589246533395\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Separate features (tweets) and labels (emotion and sentiment)\n",
        "X_train = train_df['tweet']\n",
        "y_train_emotion = train_df['emotion']\n",
        "y_train_sentiment = train_df['sentiment']\n",
        "\n",
        "X_test = test_df['tweet']\n",
        "y_test_emotion = test_df['emotion']\n",
        "y_test_sentiment = test_df['sentiment']\n",
        "\n",
        "# Combine emotion and sentiment labels\n",
        "y_train_combined = y_train_emotion + \"_\" + y_train_sentiment\n",
        "y_test_combined = y_test_emotion + \"_\" + y_test_sentiment\n",
        "\n",
        "# Vectorize the text data using TF-IDF\n",
        "vectorizer = TfidfVectorizer(sublinear_tf=True, encoding='utf-8', decode_error='ignore', stop_words='english')\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Train the logistic regression model\n",
        "lr_model = LogisticRegression(max_iter=1000)\n",
        "lr_model.fit(X_train_tfidf, y_train_combined)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_combined = lr_model.predict(X_test_tfidf)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy_combined = accuracy_score(y_test_combined, y_pred_combined)\n",
        "precision_combined = precision_score(y_test_combined, y_pred_combined, average='weighted')\n",
        "recall_combined = recall_score(y_test_combined, y_pred_combined, average='weighted')\n",
        "f1_score_combined = f1_score(y_test_combined, y_pred_combined, average='weighted')\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"Combined Evaluation Metrics:\")\n",
        "print(\"Accuracy:\", accuracy_combined)\n",
        "print(\"Precision:\", precision_combined)\n",
        "print(\"Recall:\", recall_combined)\n",
        "print(\"F1 Score:\", f1_score_combined)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BTMYDllI7tL",
        "outputId": "911abdb3-844e-4a60-863f-464682e040e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined Evaluation Metrics:\n",
            "Accuracy: 0.546\n",
            "Precision: 0.5112821046359856\n",
            "Recall: 0.546\n",
            "F1 Score: 0.4879249640768176\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#implementing decision tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Train Decision Tree model for sentiment\n",
        "dt_model_sentiment = DecisionTreeClassifier()\n",
        "dt_model_sentiment.fit(X_train_tfidf, y_train_sentiment)\n",
        "y_pred_dt_sentiment = dt_model_sentiment.predict(X_test_tfidf)\n",
        "\n",
        "# Calculate metrics for sentiment\n",
        "accuracy_dt_sentiment = accuracy_score(y_test_sentiment, y_pred_dt_sentiment)\n",
        "precision_dt_sentiment = precision_score(y_test_sentiment, y_pred_dt_sentiment, average='weighted')\n",
        "recall_dt_sentiment = recall_score(y_test_sentiment, y_pred_dt_sentiment, average='weighted')\n",
        "f1_score_dt_sentiment = f1_score(y_test_sentiment, y_pred_dt_sentiment, average='weighted')\n",
        "\n",
        "print(\"\\nDecision Tree for Sentiment:\")\n",
        "print(\"Accuracy: \", accuracy_dt_sentiment)\n",
        "print(\"Precision: \", precision_dt_sentiment)\n",
        "print(\"Recall: \", recall_dt_sentiment)\n",
        "print(\"F1 Score: \", f1_score_dt_sentiment)\n",
        "\n",
        "# Train Decision Tree model for emotion\n",
        "dt_model_emotion = DecisionTreeClassifier()\n",
        "dt_model_emotion.fit(X_train_tfidf, y_train_emotion)\n",
        "y_pred_dt_emotion = dt_model_emotion.predict(X_test_tfidf)\n",
        "\n",
        "# Calculate metrics for emotion\n",
        "accuracy_dt_emotion = accuracy_score(y_test_emotion, y_pred_dt_emotion)\n",
        "precision_dt_emotion = precision_score(y_test_emotion, y_pred_dt_emotion, average='weighted')\n",
        "recall_dt_emotion = recall_score(y_test_emotion, y_pred_dt_emotion, average='weighted')\n",
        "f1_score_dt_emotion = f1_score(y_test_emotion, y_pred_dt_emotion, average='weighted')\n",
        "\n",
        "print(\"\\nDecision Tree for Emotion:\")\n",
        "print(\"Accuracy: \", accuracy_dt_emotion)\n",
        "print(\"Precision: \", precision_dt_emotion)\n",
        "print(\"Recall: \", recall_dt_emotion)\n",
        "print(\"F1 Score: \", f1_score_dt_emotion)\n",
        "\n",
        "# Combine emotion and sentiment labels for testing\n",
        "y_test_combined = y_test_emotion + \"_\" + y_test_sentiment\n",
        "y_pred_combined = y_pred_dt_emotion + \"_\" + y_pred_dt_sentiment\n",
        "\n",
        "# Calculate metrics for combined labels\n",
        "accuracy_dt_combined = accuracy_score(y_test_combined, y_pred_combined)\n",
        "precision_dt_combined = precision_score(y_test_combined, y_pred_combined, average='weighted')\n",
        "recall_dt_combined = recall_score(y_test_combined, y_pred_combined, average='weighted')\n",
        "f1_score_dt_combined = f1_score(y_test_combined, y_pred_combined, average='weighted')\n",
        "\n",
        "print(\"\\nDecision Tree for Combined Labels:\")\n",
        "print(\"Accuracy: \", accuracy_dt_combined)\n",
        "print(\"Precision: \", precision_dt_combined)\n",
        "print(\"Recall: \", recall_dt_combined)\n",
        "print(\"F1 Score: \", f1_score_dt_combined)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UqCJiaALhQm",
        "outputId": "453e57e1-86d8-4df6-8361-1848ca3d0412"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Decision Tree for Sentiment:\n",
            "Accuracy:  0.5613333333333334\n",
            "Precision:  0.5660157203885138\n",
            "Recall:  0.5613333333333334\n",
            "F1 Score:  0.5628611988894069\n",
            "\n",
            "Decision Tree for Emotion:\n",
            "Accuracy:  0.52\n",
            "Precision:  0.5452321996286087\n",
            "Recall:  0.52\n",
            "F1 Score:  0.520391663928907\n",
            "\n",
            "Decision Tree for Combined Labels:\n",
            "Accuracy:  0.34\n",
            "Precision:  0.46635268008046205\n",
            "Recall:  0.34\n",
            "F1 Score:  0.38512234311985843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}